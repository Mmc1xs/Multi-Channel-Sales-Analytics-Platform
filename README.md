# Multi-Channel Sales Analytics Platform  
**Data Warehouse Â· ETL Pipelines Â· Near Real-Time Reporting Â· BI Dashboard**

---

## ğŸ“Œ Project Overview

This project simulates a **real-world enterprise data engineering & analytics scenario** in a large retail / telecom company.

The goal is to build an **end-to-end data platform** that enables stakeholders to:

- Monitor **daily and monthly sales performance**
- Analyze **multi-channel efficiency** (direct stores, franchise stores, online)
- Track **near real-time sales war room metrics** (15-minute windows)
- Support **management and operations decision-making** via BI dashboards

This project is designed to be **portfolio-ready** and aligned with **Data Engineer / Data Analyst / Analytics Engineer** roles.

---

## ğŸ¢ Business Scenario (Simulated)

- Industry: Retail / Telecommunications  
- Channels:
  - Direct Stores
  - Franchise Stores
  - Online
- Use Cases:
  - Daily / Monthly sales reports
  - Channel & store performance ranking
  - Sales anomaly detection
  - Near real-time sales monitoring during campaigns

---

## ğŸ—ï¸ Architecture Overview

[ Data Source ]
â””â”€ Public Dataset + Mock Data
â†“
[ Raw Layer ] (PostgreSQL)
â””â”€ raw_orders
â””â”€ raw_order_items
â””â”€ raw_product
â””â”€ raw_store
â””â”€ raw_channel
â†“
[ Staging Layer ]
â””â”€ Data cleaning, deduplication, normalization
â†“
[ Data Warehouse ]
â””â”€ Star Schema
â”œâ”€ fact_sales
â”œâ”€ dim_date
â”œâ”€ dim_product
â”œâ”€ dim_store
â”œâ”€ dim_channel
â†“
[ Data Marts ]
â””â”€ Daily / Monthly Aggregates
â””â”€ Near Real-Time (15-min window)
â†“
[ BI Layer ]
â””â”€ Management Dashboard
â””â”€ Operations & Channel Analysis
â””â”€ Near Real-Time War Room

---

## ğŸ§± Data Model (Star Schema)

**Fact Table**
- `fact_sales`
  - Grain: Order line level
  - Metrics: quantity, gross_amount, discount_amount, net_amount, margin
  - Time: order timestamp, load timestamp

**Dimension Tables**
- `dim_date` â€“ calendar, month, week, weekday
- `dim_product` â€“ SKU, category, brand
- `dim_store` â€“ store, region, channel mapping
- `dim_channel` â€“ direct / franchise / online

---

## ğŸ”„ ETL & Data Pipeline

- Language: **Python + SQL**
- Database: **PostgreSQL**

### Pipeline Layers
1. **Raw Layer**
   - Append-only ingestion
   - Full data traceability
2. **Staging Layer**
   - Deduplication
   - Missing value handling
   - Data type standardization
3. **Warehouse Layer**
   - Surrogate key generation
   - Fact & dimension loading
   - Incremental and idempotent design
4. **Data Mart**
   - Optimized for BI & real-time queries

---

## âš¡ Near Real-Time Reporting

- Time window: **Last 15 minutes**
- Refresh strategy: batch simulation (every 5 minutes)
- Metrics:
  - Sales amount
  - Order count
  - Channel/store ranking
  - Short-term anomaly detection

This design reflects **practical enterprise constraints** where streaming systems may not always be available.

---

## ğŸ“Š BI Dashboard Design

### 1. Executive Overview
- Today sales
- Month-to-date (MTD)
- MoM growth rate
- Channel contribution
- Top stores & products

### 2. Operations & Channel Analysis
- Channel vs region performance
- Store ranking & efficiency
- Average order value (AOV)
- Sales trends with moving averages

### 3. Near Real-Time War Room
- Last 15-min sales & orders
- Live store ranking
- Sales fluctuation alerts

---

## ğŸ§ª Data Quality & Reliability

Implemented checks include:
- Primary key uniqueness
- Foreign key integrity
- Sales amount validity
- Daily volume anomaly detection
- Late-arriving data monitoring

ETL jobs are designed to be **re-runnable and fault-tolerant**.

---

## ğŸ“‚ Data Source

- **Online Retail II Dataset**
  - Public transactional retail dataset
  - Extended with simulated multi-channel & store dimensions
  - Used widely for analytics and data engineering practice

---

## ğŸ› ï¸ Tech Stack

- PostgreSQL
- Python
- SQL
- Power BI / Tableau (assumed)
- Git & GitHub

---

## ğŸ¯ Project Goal

This project demonstrates the ability to:

- Design scalable data models
- Build maintainable ETL pipelines
- Perform advanced SQL analytics
- Deliver actionable BI insights
- Think from both **engineering** and **business** perspectives

---

## ğŸš€ Next Steps

- Implement raw & staging schemas
- Build mock data generator
- Develop ETL scripts
- Create BI dashboards
- Add monitoring & logging



